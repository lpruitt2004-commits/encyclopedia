export const articles = [
  {
    id: 1,
    title: "Introduction to Progressive Web Apps",
    category: "Technology",
    summary:
      "Learn about Progressive Web Apps (PWAs) and how they combine the best of web and mobile applications to provide a seamless user experience.",
    content:
      "Progressive Web Apps (PWAs) represent a revolutionary approach to web development that combines the best features of web and mobile applications. These applications use modern web capabilities to deliver app-like experiences to users, providing reliability, speed, and engagement. PWAs work offline, send push notifications, and can be installed on a user's home screen, all while maintaining the reach and accessibility of the web. They are built using standard web technologies including HTML, CSS, and JavaScript, but are enhanced with service workers and web app manifests to provide native-like functionality.",
    author: "Technology Editors",
    date: "2024-12-04",
  },
  {
    id: 2,
    title: "Mobile-First Design Principles",
    category: "Design",
    summary:
      "Discover the key principles of mobile-first design and why it's crucial for modern web development in an increasingly mobile world.",
    content:
      "Mobile-first design is a strategic approach to web design that prioritizes the mobile user experience from the very beginning of the design process. Rather than designing for desktop and then adapting for smaller screens, mobile-first design starts with the smallest screen and progressively enhances the experience for larger devices. This methodology forces designers to focus on the most essential content and features, ensuring that the core user experience is optimized for the constraints of mobile devices including limited screen space, touch interfaces, and variable network conditions. Key principles include touch-friendly interfaces, simplified navigation, optimized images and media, and progressive enhancement for larger screens.",
    author: "Design Editors",
    date: "2024-12-03",
  },
  {
    id: 3,
    title: "React Hooks Explained",
    category: "Programming",
    summary:
      "A comprehensive guide to understanding and using React Hooks to build modern, functional React components.",
    content:
      "React Hooks revolutionized the way developers write React components when they were introduced in React 16.8. Hooks are functions that let you use state and other React features in functional components, eliminating the need for class components in most cases. The most commonly used hooks include useState for managing component state, useEffect for handling side effects like data fetching and subscriptions, useContext for accessing React context, and useCallback and useMemo for performance optimization. Hooks follow specific rules: they must be called at the top level of a component and cannot be called inside loops, conditions, or nested functions. Custom hooks can be created to extract and reuse stateful logic across multiple components, promoting code reusability and cleaner component architecture.",
    author: "Programming Editors",
    date: "2024-12-02",
  },
  {
    id: 4,
    title: "Understanding Service Workers",
    category: "Technology",
    summary:
      "Explore how service workers enable offline functionality and improve performance in Progressive Web Apps.",
    content: "Service workers are scripts that run in the background...",
    author: "Tech Encyclopedia",
    date: "2024-12-01",
  },
  {
    id: 5,
    title: "CSS Grid Layout Guide",
    category: "Design",
    summary:
      "Master CSS Grid Layout to create complex, responsive web layouts with ease and precision.",
    content: "CSS Grid Layout is a powerful two-dimensional layout system...",
    author: "Design Encyclopedia",
    date: "2024-11-30",
  },
  {
    id: 6,
    title: "JavaScript ES6+ Features",
    category: "Programming",
    summary:
      "Explore the modern features of JavaScript including arrow functions, async/await, and destructuring.",
    content: "ES6 and beyond brought significant improvements to JavaScript...",
    author: "Code Encyclopedia",
    date: "2024-11-29",
  },
  {
    id: 7,
    title: "The Solar System",
    category: "Science",
    summary:
      "Explore our cosmic neighborhood, from the Sun to the outer reaches of the Kuiper Belt and beyond.",
    content:
      "The Solar System is a gravitationally bound system consisting of the Sun and the objects that orbit it. The Sun, a G-type main-sequence star, contains 99.86% of the system's mass and dominates it gravitationally. The eight planetsâ€”Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptuneâ€”are divided into inner terrestrial planets and outer gas giants. The Solar System also contains dwarf planets, moons, asteroids, comets, and interplanetary dust. It formed approximately 4.6 billion years ago from the gravitational collapse of a region within a large molecular cloud. The planets formed through accretion of material in the protoplanetary disk surrounding the young Sun. Understanding our Solar System helps us comprehend planetary formation and the potential for life elsewhere in the universe.",
    author: "Science Editors",
    date: "2024-11-28",
  },
  {
    id: 8,
    title: "Ancient Rome",
    category: "History",
    summary:
      "Discover the rise and fall of one of history's greatest civilizations and its lasting impact on Western culture.",
    content:
      "Ancient Rome was a civilization that began as a small settlement on the Tiber River in central Italy around 753 BCE and grew to become one of the largest empires in history. The Roman civilization progressed through three major phases: the Roman Kingdom (753-509 BCE), the Roman Republic (509-27 BCE), and the Roman Empire (27 BCE-476 CE in the West, continuing until 1453 CE in the East as the Byzantine Empire). Rome's contributions to Western civilization are immeasurable, including advances in engineering (aqueducts, roads, concrete), law (Roman law became the foundation for many modern legal systems), language (Latin influenced Romance languages), government (republican principles), and culture. At its height, the Roman Empire controlled territories spanning from Britain to North Africa and from Spain to the Middle East, facilitating trade, cultural exchange, and the spread of ideas across three continents.",
    author: "History Editors",
    date: "2024-11-27",
  },
  {
    id: 9,
    title: "Quantum Mechanics",
    category: "Science",
    summary:
      "An introduction to the fundamental theory in physics that describes nature at the smallest scales of energy levels.",
    content:
      "Quantum mechanics is a fundamental theory in physics that describes the behavior of matter and energy at the atomic and subatomic levels. Developed in the early 20th century by physicists including Max Planck, Albert Einstein, Niels Bohr, Werner Heisenberg, and Erwin SchrÃ¶dinger, quantum mechanics revolutionized our understanding of nature. Key principles include wave-particle duality (particles can exhibit both wave and particle properties), the uncertainty principle (certain pairs of physical properties cannot be simultaneously known to arbitrary precision), quantum superposition (systems can exist in multiple states simultaneously until measured), and quantum entanglement (particles can be correlated in ways that seem to defy classical physics). Quantum mechanics has led to numerous technological applications including transistors, lasers, MRI machines, and is the foundation for emerging technologies like quantum computing.",
    author: "Science Editors",
    date: "2024-11-26",
  },
  {
    id: 10,
    title: "The Renaissance",
    category: "History",
    summary:
      "Explore the cultural rebirth that transformed European art, science, and philosophy from the 14th to 17th centuries.",
    content:
      "The Renaissance was a period of cultural, artistic, political, and economic rebirth that began in Italy in the 14th century and spread throughout Europe, lasting until the 17th century. The term 'Renaissance' means 'rebirth' and refers to the renewed interest in the classical learning and values of ancient Greece and Rome. This period saw unprecedented achievements in art with masters like Leonardo da Vinci, Michelangelo, and Raphael; advances in science through figures like Galileo and Copernicus; literary innovations from writers like Shakespeare and Dante; and philosophical developments in humanism that emphasized human potential and achievements. The Renaissance marked the transition from the Middle Ages to modernity, fundamentally changing how Europeans viewed themselves and the world around them. Key factors enabling the Renaissance included increased trade and wealth in Italian city-states, the fall of Constantinople bringing Greek scholars to the West, and the invention of the printing press facilitating the spread of knowledge.",
    author: "History Editors",
    date: "2024-11-25",
  },
  {
    id: 11,
    title: "Phi-3 Mini Complete Guide",
    category: "AI",
    summary:
      "Master Microsoft's Phi-3 Mini (3.8B) - A comprehensive guide covering setup, prompting techniques, advanced features, and optimization for M1 MacBook Air.",
    content: `# Phi-3 Mini (3.8B) - Complete Guide

## Overview
Phi-3 Mini is Microsoft's compact yet powerful language model with 3.8 billion parameters, optimized for efficiency without sacrificing capability. It's perfect for M1 MacBook Air.

## Installation & Setup

### Basic Installation
\`\`\`bash
# Pull the model
ollama pull phi3:mini

# Run interactively
ollama run phi3:mini

# Run with custom parameters
ollama run phi3:mini --temperature 0.7 --top-p 0.9
\`\`\`

### Model Variants
- \`phi3:mini\` - Standard 3.8B model (recommended)
- \`phi3:medium\` - 14B model (requires more RAM)

## Advanced Usage

### CLI Parameters
\`\`\`bash
# Temperature (0.0-2.0): Lower = more focused, Higher = more creative
ollama run phi3:mini --temperature 0.3

# Top-P (nucleus sampling): 0.1-1.0
ollama run phi3:mini --top-p 0.9

# Context window
ollama run phi3:mini --num-ctx 4096

# Seed for reproducibility
ollama run phi3:mini --seed 42
\`\`\`

### API Usage
\`\`\`bash
# Start Ollama server
ollama serve

# Query via API
curl http://localhost:11434/api/generate -d '{
  "model": "phi3:mini",
  "prompt": "Explain quantum computing",
  "stream": false
}'
\`\`\`

## Prompting Best Practices

### System Prompts
\`\`\`
You are a helpful AI assistant. Be concise and accurate.
Focus on practical solutions. Explain complex topics simply.
\`\`\`

### Few-Shot Learning
\`\`\`
Q: What is 2+2?
A: 4

Q: What is the capital of France?
A: Paris

Q: What is photosynthesis?
A: [Your question here]
\`\`\`

### Chain-of-Thought Prompting
\`\`\`
Let's solve this step by step:
1. First, identify the problem
2. Then, break it down
3. Finally, provide the solution
\`\`\`

## Performance Optimization

### Memory Management
- **8GB RAM**: Use default settings, close other apps
- **16GB RAM**: Increase context window to 8192
- Monitor with: \`ollama ps\`

### Speed Optimization
\`\`\`bash
# Reduce context for faster responses
ollama run phi3:mini --num-ctx 2048

# Batch processing
cat prompts.txt | while read prompt; do
  ollama run phi3:mini "$prompt" --verbose false
done
\`\`\`

## Use Cases & Examples

### Code Review
\`\`\`
Review this code and suggest improvements:
[paste code]
\`\`\`

### Writing Assistant
\`\`\`
Rewrite this paragraph to be more professional:
[your text]
\`\`\`

### Question Answering
\`\`\`
Based on this context: [context]
Answer: [question]
\`\`\`

### Summarization
\`\`\`
Summarize this article in 3 bullet points:
[article text]
\`\`\`

## Tips & Tricks

1. **Structured Output**: Ask for JSON, markdown, or specific formats
2. **Role Playing**: "Act as a [role]" for specialized responses
3. **Constraints**: Set word limits, tone, style requirements
4. **Iteration**: Refine outputs with follow-up prompts
5. **Context Management**: Clear history when switching topics

## Common Issues & Solutions

### Slow Performance
- Reduce context window
- Close background apps
- Use quantized versions

### Inconsistent Outputs
- Set seed for reproducibility
- Lower temperature for consistency
- Use more specific prompts

### Memory Issues
- Reduce num_ctx parameter
- Monitor with Activity Monitor
- Restart Ollama service

## Integration Examples

### Python Script
\`\`\`python
import requests

def query_phi3(prompt):
    response = requests.post('http://localhost:11434/api/generate',
        json={"model": "phi3:mini", "prompt": prompt, "stream": False})
    return response.json()['response']
\`\`\`

### Node.js Script
\`\`\`javascript
const axios = require('axios');

async function queryPhi3(prompt) {
    const response = await axios.post('http://localhost:11434/api/generate', {
        model: 'phi3:mini',
        prompt: prompt,
        stream: false
    });
    return response.data.response;
}
\`\`\`

## Model Information
- **Parameters**: 3.8B
- **Context Length**: 4K (expandable to 128K)
- **Training Data**: Up to October 2023
- **Languages**: Primarily English
- **License**: MIT`,
    author: "AI Models Encyclopedia",
    date: "2024-12-04",
  },
  {
    id: 12,
    title: "CodeLlama 7B Complete Guide",
    category: "AI",
    summary:
      "Everything you need to know about CodeLlama 7B-Instruct - From setup to advanced code generation, debugging, and optimization techniques.",
    content: `# CodeLlama 7B-Instruct - Complete Guide

## Overview
CodeLlama is Meta's specialized code generation model built on Llama 2. The 7B-Instruct variant is optimized for conversational coding assistance and runs efficiently on M1 MacBook Air.

## Installation & Setup

### Basic Installation
\`\`\`bash
# Pull CodeLlama 7B Instruct
ollama pull codellama:7b-instruct

# Run interactively
ollama run codellama:7b-instruct

# Alternative versions
ollama pull codellama:7b          # Base model
ollama pull codellama:7b-code     # Code completion
ollama pull codellama:7b-python   # Python specialized
\`\`\`

## Model Variants Explained

- **7b-instruct**: Best for chat, explanations, conversational coding
- **7b**: Raw model for completions
- **7b-code**: Optimized for code completion
- **7b-python**: Python-specific variant

## Advanced Usage

### Code Generation
\`\`\`bash
ollama run codellama:7b-instruct "Write a Python function to calculate fibonacci numbers"
\`\`\`

### Code Explanation
\`\`\`bash
ollama run codellama:7b-instruct "Explain this code: [paste code]"
\`\`\`

### Debugging
\`\`\`bash
ollama run codellama:7b-instruct "Debug this code and explain the error: [code]"
\`\`\`

### Code Review
\`\`\`bash
ollama run codellama:7b-instruct "Review this code for security issues: [code]"
\`\`\`

## Optimal Parameters

\`\`\`bash
# For precise code generation
ollama run codellama:7b-instruct \\
  --temperature 0.2 \\
  --top-p 0.95 \\
  --repeat-penalty 1.1

# For creative solutions
ollama run codellama:7b-instruct \\
  --temperature 0.7 \\
  --top-p 0.9

# For consistent outputs
ollama run codellama:7b-instruct \\
  --temperature 0.1 \\
  --seed 42
\`\`\`

## Programming Languages Supported

**Excellent Support:**
- Python, JavaScript/TypeScript, C++, Java, C#
- Go, Rust, PHP, Ruby, Swift

**Good Support:**
- Kotlin, Scala, R, Shell scripting
- SQL, HTML/CSS

## Prompting Techniques

### Fill-in-the-Middle (FIM)
\`\`\`python
# Use <FILL> placeholder
def calculate_sum(numbers):
    <FILL>
    return total
\`\`\`

### Specify Language
\`\`\`
Generate a Python function that:
- Takes a list of numbers
- Returns the median value
- Handles edge cases
\`\`\`

### Provide Context
\`\`\`
In a React application using TypeScript and hooks,
create a custom hook for data fetching with error handling.
\`\`\`

### Request Specific Format
\`\`\`
Write a REST API endpoint in Express.js with:
- Input validation
- Error handling
- JSDoc comments
- TypeScript types
\`\`\`

## Best Practices

### 1. Be Specific
âŒ "Write a sorting function"
âœ… "Write a Python function that implements quicksort with type hints and docstrings"

### 2. Provide Examples
\`\`\`
Similar to this pattern:
[example code]

Now create: [your requirement]
\`\`\`

### 3. Iterative Refinement
\`\`\`
1. Generate initial code
2. Ask for optimizations
3. Request error handling
4. Add documentation
\`\`\`

### 4. Multi-Step Approach
\`\`\`
Step 1: Write the function signature
Step 2: Implement the core logic
Step 3: Add error handling
Step 4: Write unit tests
\`\`\`

## Advanced Features

### Code Completion Mode
\`\`\`bash
# Use the code variant for completions
ollama run codellama:7b-code
\`\`\`

### Multi-File Context
\`\`\`
Given these files:
--- file1.py ---
[content]
--- file2.py ---
[content]

Create file3.py that integrates both.
\`\`\`

### Test Generation
\`\`\`
For this function:
[function code]

Generate pytest unit tests covering:
- Happy path
- Edge cases
- Error conditions
\`\`\`

## Integration Examples

### VS Code Integration (via Ollama)
\`\`\`bash
# Install Ollama extension
# Configure to use codellama:7b-instruct
\`\`\`

### CLI Helper Script
\`\`\`bash
#!/bin/bash
# Save as codellama-help.sh

echo "Enter your code question:"
read -r question

ollama run codellama:7b-instruct "$question" \\
  --temperature 0.2 \\
  --top-p 0.95
\`\`\`

### Python Wrapper
\`\`\`python
import subprocess
import json

def codellama_generate(prompt, temperature=0.2):
    cmd = [
        'ollama', 'run', 'codellama:7b-instruct',
        prompt,
        '--temperature', str(temperature)
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.stdout

# Usage
code = codellama_generate("Write a binary search in Python")
print(code)
\`\`\`

## Performance Tips

### Memory Optimization
- Close unused applications
- Monitor: \`ollama ps\`
- Reduce context if needed: \`--num-ctx 2048\`

### Speed Optimization
- Use code variant for completions (faster)
- Lower temperature for deterministic output
- Batch similar requests

## Common Use Cases

### 1. Code Translation
\`\`\`
Convert this JavaScript code to Python:
[JS code]
\`\`\`

### 2. Refactoring
\`\`\`
Refactor this code to use modern ES6+ features:
[old code]
\`\`\`

### 3. Documentation
\`\`\`
Add comprehensive JSDoc comments to this code:
[code]
\`\`\`

### 4. Bug Fixing
\`\`\`
This code has a bug. Find and fix it:
[buggy code]
Error message: [error]
\`\`\`

### 5. Code Optimization
\`\`\`
Optimize this algorithm for better time complexity:
[code]
\`\`\`

## Limitations

- **Context Window**: 4K tokens (about 3000 words)
- **Training Cutoff**: 2023 data
- **No Internet Access**: Can't fetch current docs
- **Language Bias**: Best with common languages

## Troubleshooting

### Issue: Incomplete code
**Solution**: Ask to continue or be more specific

### Issue: Wrong language
**Solution**: Explicitly specify language in prompt

### Issue: Outdated syntax
**Solution**: Request "modern" or "latest" standards

## Model Information
- **Parameters**: 7B
- **Context Length**: 4K tokens
- **Training**: Code-focused dataset
- **License**: Llama 2 Community License`,
    author: "AI Models Encyclopedia",
    date: "2024-12-04",
  },
  {
    id: 13,
    title: "Inter-Model Prompting: Phi-3 & CodeLlama",
    category: "AI",
    summary:
      "Advanced techniques for using Phi-3 Mini and CodeLlama together - Chain prompting, specialized workflows, and collaborative AI problem-solving.",
    content: `# Inter-Model Prompting: Phi-3 Mini & CodeLlama

## Overview
While AI models can't directly "prompt" each other in real-time, you can create powerful workflows where outputs from one model become inputs to another, leveraging each model's strengths.

## Why Use Both Models Together?

### Phi-3 Mini Strengths
- General reasoning and planning
- Natural language understanding
- Requirements analysis
- Documentation and explanations
- Project planning

### CodeLlama Strengths
- Code generation
- Programming best practices
- Language-specific optimizations
- Debugging and error handling
- Code review

## Workflow Patterns

### Pattern 1: Plan â†’ Implement

**Step 1: Use Phi-3 for Planning**
\`\`\`bash
ollama run phi3:mini "I need to build a REST API for a todo app. 
Create a detailed implementation plan including:
- Required endpoints
- Data models
- Tech stack recommendations
- Security considerations"
\`\`\`

**Step 2: Use CodeLlama for Implementation**
\`\`\`bash
ollama run codellama:7b-instruct "Based on this plan:
[paste Phi-3 output]

Generate the Express.js code for the POST /todos endpoint"
\`\`\`

### Pattern 2: Understand â†’ Code

**Step 1: Phi-3 Explains Concept**
\`\`\`bash
ollama run phi3:mini "Explain the Observer pattern in software design.
Include use cases and when to apply it."
\`\`\`

**Step 2: CodeLlama Implements**
\`\`\`bash
ollama run codellama:7b-instruct "Implement the Observer pattern in TypeScript
with a practical example of a stock price monitoring system"
\`\`\`

### Pattern 3: Code â†’ Review â†’ Improve

**Step 1: CodeLlama Generates Code**
\`\`\`bash
ollama run codellama:7b-instruct "Create a Python class for managing user authentication"
\`\`\`

**Step 2: Phi-3 Reviews**
\`\`\`bash
ollama run phi3:mini "Review this authentication code for:
- Security vulnerabilities
- Design patterns
- Scalability issues
[paste code]"
\`\`\`

**Step 3: CodeLlama Improves**
\`\`\`bash
ollama run codellama:7b-instruct "Improve this code based on review:
Code: [original code]
Review: [Phi-3 feedback]"
\`\`\`

### Pattern 4: Requirements â†’ Architecture â†’ Code

**Step 1: Phi-3 Analyzes Requirements**
\`\`\`bash
ollama run phi3:mini "Analyze these requirements and suggest architecture:
[project requirements]"
\`\`\`

**Step 2: Phi-3 Creates Technical Spec**
\`\`\`bash
ollama run phi3:mini "Based on the architecture, create detailed technical specifications for: [component]"
\`\`\`

**Step 3: CodeLlama Implements**
\`\`\`bash
ollama run codellama:7b-instruct "Implement this component:
Spec: [technical spec]"
\`\`\`

## Automation Scripts

### Bash Script: Chain Prompting
\`\`\`bash
#!/bin/bash
# chain-prompt.sh

# Step 1: Plan with Phi-3
echo "Planning phase..."
plan=\$(ollama run phi3:mini "Create implementation plan for: $1" --verbose false)

echo "Plan created:"
echo "$plan"
echo ""

# Step 2: Implement with CodeLlama
echo "Implementation phase..."
ollama run codellama:7b-instruct "Implement this plan: $plan"
\`\`\`

Usage:
\`\`\`bash
chmod +x chain-prompt.sh
./chain-prompt.sh "a user authentication system"
\`\`\`

### Python Script: Interactive Workflow
\`\`\`python
#!/usr/bin/env python3
import subprocess
import json

def query_phi3(prompt):
    """Query Phi-3 Mini"""
    result = subprocess.run(
        ['ollama', 'run', 'phi3:mini', prompt, '--verbose', 'false'],
        capture_output=True, text=True
    )
    return result.stdout.strip()

def query_codellama(prompt):
    """Query CodeLlama"""
    result = subprocess.run(
        ['ollama', 'run', 'codellama:7b-instruct', prompt, '--verbose', 'false'],
        capture_output=True, text=True
    )
    return result.stdout.strip()

def workflow_plan_and_code(task):
    """Complete workflow: plan with Phi-3, code with CodeLlama"""
    
    # Step 1: Planning
    print("ðŸ” Planning with Phi-3...")
    plan_prompt = f"Create a detailed implementation plan for: {task}"
    plan = query_phi3(plan_prompt)
    print(f"\\nPlan:\\n{plan}\\n")
    
    # Step 2: Implementation
    print("ðŸ’» Coding with CodeLlama...")
    code_prompt = f"Implement this plan in code:\\n{plan}"
    code = query_codellama(code_prompt)
    print(f"\\nCode:\\n{code}\\n")
    
    # Step 3: Documentation
    print("ðŸ“ Documenting with Phi-3...")
    doc_prompt = f"Write user documentation for this code:\\n{code}"
    docs = query_phi3(doc_prompt)
    print(f"\\nDocumentation:\\n{docs}")
    
    return {"plan": plan, "code": code, "docs": docs}

# Usage
if __name__ == "__main__":
    task = input("What would you like to build? ")
    workflow_plan_and_code(task)
\`\`\`

### Node.js Script: Collaborative Review
\`\`\`javascript
#!/usr/bin/env node
const { exec } = require('child_process');
const util = require('util');
const execPromise = util.promisify(exec);

async function queryModel(model, prompt) {
    const { stdout } = await execPromise(
        \`ollama run \${model} "\${prompt}" --verbose false\`
    );
    return stdout.trim();
}

async function collaborativeCodeReview(code) {
    // Step 1: CodeLlama technical review
    console.log('ðŸ”§ CodeLlama technical review...');
    const techReview = await queryModel(
        'codellama:7b-instruct',
        \`Review this code for bugs and optimizations:\\n\${code}\`
    );
    console.log('\\nTechnical Review:', techReview);
    
    // Step 2: Phi-3 architecture review
    console.log('\\nðŸ—ï¸  Phi-3 architecture review...');
    const archReview = await queryModel(
        'phi3:mini',
        \`Review architecture and design patterns in:\\n\${code}\`
    );
    console.log('\\nArchitecture Review:', archReview);
    
    // Step 3: Combined improvements
    console.log('\\nâœ¨ Generating improvements...');
    const improvements = await queryModel(
        'codellama:7b-instruct',
        \`Improve this code based on reviews:
        Code: \${code}
        Technical: \${techReview}
        Architecture: \${archReview}\`
    );
    console.log('\\nImproved Code:', improvements);
    
    return { techReview, archReview, improvements };
}

// Usage
const code = process.argv[2] || 'function test() { return true; }';
collaborativeCodeReview(code);
\`\`\`

## Advanced Techniques

### 1. Iterative Refinement
\`\`\`
Loop:
  CodeLlama â†’ generate code
  Phi-3 â†’ review
  CodeLlama â†’ refine
Until: Phi-3 approves
\`\`\`

### 2. Specialized Roles
- **Phi-3**: Project manager, architect, documenter
- **CodeLlama**: Developer, reviewer, debugger

### 3. Context Sharing
Save outputs to files and reference them:
\`\`\`bash
ollama run phi3:mini "Plan..." > plan.txt
ollama run codellama:7b-instruct "Implement: \$(cat plan.txt)"
\`\`\`

### 4. Decision Trees
\`\`\`
Phi-3: Analyze problem â†’ Choose approach
  â”œâ”€ Approach A â†’ CodeLlama implements
  â””â”€ Approach B â†’ CodeLlama implements
Phi-3: Compare results â†’ Select best
\`\`\`

## Real-World Workflows

### Full-Stack Development
1. **Phi-3**: Analyze requirements, design architecture
2. **CodeLlama**: Generate backend API
3. **CodeLlama**: Generate frontend components
4. **Phi-3**: Review integration, suggest improvements
5. **CodeLlama**: Implement improvements
6. **Phi-3**: Generate documentation

### Debugging Workflow
1. **User**: Provides error and code
2. **Phi-3**: Analyzes error context
3. **CodeLlama**: Identifies bug location
4. **Phi-3**: Explains root cause
5. **CodeLlama**: Provides fix
6. **Phi-3**: Suggests prevention strategies

### Learning Workflow
1. **Phi-3**: Explains concept
2. **CodeLlama**: Shows code examples
3. **Phi-3**: Answers questions
4. **CodeLlama**: Creates practice exercises
5. **Phi-3**: Reviews solutions

## Best Practices

1. **Clear Handoffs**: Be explicit about context when switching models
2. **Save Outputs**: Keep model outputs for reference
3. **Validate Results**: Don't blindly trust; review outputs
4. **Iterate**: Use multiple rounds for complex tasks
5. **Document Flow**: Track which model did what

## Limitations

- No real-time communication between models
- Manual orchestration required
- Context window limits (4K tokens each)
- Sequential processing only
- Requires scripting for automation

## Tips for Success

1. **Use Phi-3 for** "what" and "why"
2. **Use CodeLlama for** "how" (implementation)
3. **Start broad** (Phi-3) then get specific (CodeLlama)
4. **Verify outputs** at each step
5. **Build reusable scripts** for common workflows`,
    author: "AI Models Encyclopedia",
    date: "2024-12-04",
  },
];

export const categories = [
  "All",
  "AI",
  "Technology",
  "Design",
  "Programming",
  "Science",
  "History",
];
